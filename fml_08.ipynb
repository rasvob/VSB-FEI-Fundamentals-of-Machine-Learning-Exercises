{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b61190-61c1-4dd2-a9ec-acbadc8a52ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Machine Learning - Exercise 8\n",
    "Goal of the excercise is to learn how to use Scikit-learn library for a classification tasks and evaluate the performance of the proposed models.\n",
    "\n",
    "![meme04](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_08_meme_04.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c5553-ad01-4d43-93fb-50c085f09a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, auc\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a2f23-7783-4218-b011-1690c65805c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Dictionary\n",
    "\n",
    "|Variable|Definition|Key|\n",
    "|:-------|:-------|:--------|\n",
    "|survival|Survival|0 = No, 1 = Yes|\n",
    "|pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex|Sex||\n",
    "|Age|Age in years||\n",
    "|sibsp|# of siblings / spouses aboard the Titanic||\n",
    "|parch|# of parents / children aboard the Titanic||\n",
    "|ticket|Ticket number||\n",
    "|fare|Passenger fare||\n",
    "|cabin|Cabin number||\n",
    "|embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd915f1-bf25-4b51-8f86-863cd5a891c4",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "* Decision tree https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "* Train test split https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "* Accuracy https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "* Metrics https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "* K-Fold CV https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n",
    "* Random forest https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d685ada-68b5-474a-84d5-5bfacd4a9eca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üéØ What is our goal for this dataset?\n",
    "* üîé What are the input features?\n",
    "* üîé What is the output?\n",
    "* üîé What should the model do?\n",
    "\n",
    "## Load the titanic.csv dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9043cd-4e41-40b0-93e1-712d94d122b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/master/datasets/titanic.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31066055-7548-4214-911c-0c0f1e39a212",
   "metadata": {},
   "source": [
    "# üìä Each task starts with basic exploration of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3d400-65c8-4beb-bf62-5a524eb2eacf",
   "metadata": {},
   "source": [
    "## How many passangers survived?\n",
    "* Are the labels balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1dfcb0-ac1c-4271-986a-fc5c017c760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e2c89-99da-455d-a856-ecb388c43d99",
   "metadata": {},
   "source": [
    "# üí° We need to pre-process the data first before training any ML model\n",
    "* We want to use only numerical attributes as a model features\n",
    "* Certain attributes need to be dropped and some of them can be encoded\n",
    "\n",
    "![meme01](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_08_meme_01.jpg?raw=true)\n",
    "\n",
    "## Which features could be encoded and which methods would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1a75a-842a-4bb9-9d96-9f41e82faba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925eb694-ad0f-4c53-b524-c9f8ea3f7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052ca31-34be-4775-b0d3-15c38e0b0593",
   "metadata": {},
   "source": [
    "## How many values are missing in the individual attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa840886-9c82-4fe5-8407-487a4de85ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650ab79-9cbe-4372-ac7f-6dc8dbc0461c",
   "metadata": {},
   "source": [
    "# üîé Which features would you drop and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2f054-6572-4aa5-a3b5-3c9a24ed11e7",
   "metadata": {},
   "source": [
    "## Let's drop Name and Ticket features - these have no use for us now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816c0bb-03c7-4b3b-be9b-af574c19728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Name', 'Ticket'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1214c-278f-4fa6-8259-989ce7192b66",
   "metadata": {},
   "source": [
    "# üö§ Extract the deck identifier from the Cabin feature\n",
    "* üí° A = top deck, G = lowest deck\n",
    "  \n",
    "1) Change type to string\n",
    "   \n",
    "2) Filter the first letter using *apply* function\n",
    "   \n",
    "3) If the value is *nan* use *U* value as an replacement - this will mark the passangers with missing Cabin value\n",
    "   \n",
    "4) Replace the T value with A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f6d85-aee5-4649-ba4b-dbff92c97a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Cabin = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e72ef-5465-4660-9f2f-78d449e1ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d8231-19b8-470d-a3a0-31efc63ad0fc",
   "metadata": {},
   "source": [
    "# ‚ö† The Age feature is tricky, we have multiple solutions for dealing with missing values, e.g.:\n",
    "\n",
    "1) Drop the feature\n",
    "\n",
    "2) Take the mean/median value to replace the missing value\n",
    "\n",
    "3) Take a random list of ages that maintains the original statistical summary values\n",
    "\n",
    "4) Use a model to predict values based on the existing values\n",
    "\n",
    "## We will use the second option ‚úå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa600a-bcae-4092-a528-eb4254bd93ea",
   "metadata": {},
   "source": [
    "## Check the boxplot *before* and *after* the replacement\n",
    "* üîé Is there any change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042d5ec-7134-4019-b5fb-82847b3e8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.Age).set_title('Before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5992687-87c1-476b-b674-0e4767e8f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Age = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd2688-f10e-4cfe-a38f-16dd6f462170",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.Age).set_title('After')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d69cd4-dfe3-4e37-9997-8fe135fa12dc",
   "metadata": {},
   "source": [
    "## Two passangers don't have the *Embarked* feature filled - we can drop these two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb68d26-598e-4e2d-b782-63b6c38a70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a377bb-ad92-4952-bff0-642e9f68efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71aa04-f392-4bbe-a2c3-9acd871665f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The last step of the pre-processing pipeline is to encode *Sex*, *Cabin* and *Embarked* features üëä\n",
    "* We will use one-hot encoding for *Sex* and *Embarked* and Ordinal encoding for Cabin\n",
    "* Specify the encoding scheme for the ordinal encoding using an array in a form ['first', 'second', 'third', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4dcea-3112-4988-ba71-90cd87c1248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_categories = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'U']\n",
    "enc_cabin = OrdinalEncoder(categories=[cabin_categories])\n",
    "enc_cabin.fit_transform(df[['Cabin']])[:, 0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d5b3f-c8af-457f-912a-509efebf6e58",
   "metadata": {},
   "source": [
    "## Encode *Cabin* feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec43f04-0b47-4ef5-8a63-b1e2c0a3f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'Cabin'] = enc_cabin.fit_transform(df[['Cabin']])[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548e037-a481-42c1-bdc5-68e50a3af422",
   "metadata": {},
   "source": [
    "## Encode *Sex* feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cd80d-6c2c-4f8e-8e52-640314633c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_categories = ['male', 'female']\n",
    "enc_sex = OrdinalEncoder(categories=[sex_categories])\n",
    "df.loc[:, 'Sex'] = enc_sex.fit_transform(df[['Sex']])[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64375798-78af-45b6-84c9-e702f346c62c",
   "metadata": {},
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e22af-b485-4721-b886-1b03eeca28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f0450-9a91-49f3-a663-8088f2a951f0",
   "metadata": {},
   "source": [
    "## The final step is to encode the *Embarked* using a one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18869dd-aca4-4ba0-9cb4-81d8891ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cca6de-ab80-4247-a025-bc1940fb0c9a",
   "metadata": {},
   "source": [
    "## Concat the original `df` with a `pd.get_dummies` encoding result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32c1d1-cd69-4f07-b9fa-62a075b57460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1).drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cba21-7214-4cd2-acd6-e7507ffcba02",
   "metadata": {},
   "source": [
    "# The dataset is finally ready for the machine learning model training! üòç\n",
    "* Let's take a one last look if everything is OK and we are good to go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d78f97-2c46-4c5a-8297-d1effbeaa5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0affd869-d673-4af1-b523-eb27e36bba64",
   "metadata": {},
   "source": [
    "# üöÄ Let's start with splitting the data into the input and output part\n",
    "* Usually named as a *X* and *y* variables\n",
    "* What is the input and output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f021d0-28b1-4c2a-8e03-6070d3ace1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.loc[:, df.columns != 'Survived'], df.loc[:, 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c412ed1-20ff-47a8-9dfd-4f26a69cc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d44f9-ada3-4ed0-9b15-4c5c4d699b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c161813-24a7-46b5-9301-792c93810629",
   "metadata": {
    "tags": []
   },
   "source": [
    "# We usually want to split the data into two sets called `train` and `test`\n",
    "* üîé Why do we do that?\n",
    "* Note that number of rows in the *X* and *y* in the Train/Test part of the data has to be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4621df-36a4-4097-bb2c-4c8325f3b882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08cdb399-d902-428c-9fbc-fe985a446b03",
   "metadata": {},
   "source": [
    "# üå≥ Create the Decision tree classifier instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b94962-d1f7-4451-a460-4f88d4cfe95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0509a62-5a8e-4f21-b229-b10d6a30f865",
   "metadata": {},
   "source": [
    "## Use `fit()` method for training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f2156-e441-4321-ba53-69f59c648980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b97786-6284-43fe-9f48-e52370106d9d",
   "metadata": {},
   "source": [
    "## Lets use trained model for the prediction of the survival of the passenger\n",
    "* üí° Get predictions via the `predict()` method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e30c4-95e9-4625-967e-587b5099de67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e17f70-c136-4eb0-b362-f19a8b787eb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How can we evaluate our model?\n",
    "* There are multiple metrics used: Accuracy, Recall, Precision, F1-Score, etc.\n",
    "* üí° Very useful is also creating a confusion matrix\n",
    "\n",
    "# üîé How can we select the metric?\n",
    "* üí° Accuracy and F1-Score are the most universal metrics\n",
    "\n",
    "## üîé When is **Accuracy** unsuitable?\n",
    "\n",
    "![meme02](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_08_meme_02.jpg?raw=true)\n",
    "\n",
    "# Take a look at this [article](https://builtin.com/data-science/precision-and-recall) and [wiki](https://en.wikipedia.org/wiki/Precision_and_recall) about precision and recall\n",
    "* üí° Beware the fact that as we increase precision, we decrease recall and vice-versa.\n",
    "\n",
    "* **Precision** is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "    * The question that precision answer is of all passengers that labeled as survived, how many actually survived?\n",
    "    * High precision relates to the low false positive rate.\n",
    "\n",
    "\n",
    "* **Recall** is the ratio of correctly predicted positive observations to the all observations in actual class - yes.\n",
    "    * The question recall answers is: Of all the passengers that truly survived, how many did we label?\n",
    "\n",
    "* **F1 Score** is the harmonic mean of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "    * Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution.\n",
    "    * üí° **F1 works best if false positives and false negatives have similar cost**\n",
    "        * If the cost of false positives and false negatives are very different, it‚Äôs better to look at both Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7aee0b-44d2-4609-95d9-c6ea223d717b",
   "metadata": {
    "tags": []
   },
   "source": [
    "$ConfMatrix = \\begin{bmatrix}\n",
    "TP & FN\\\\\n",
    "FP & TN\n",
    "\\end{bmatrix}$\n",
    "\n",
    "## Let's take a look at an example:\n",
    "$|1| = 10$\n",
    "\n",
    "$|0| = 90$\n",
    "\n",
    "$M = \\begin{bmatrix}\n",
    "1 & 9\\\\\n",
    "0 & 90\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN} = \\frac{1+90}{1+90+0+9} = \\frac{91}{100} = 0.91$\n",
    "\n",
    "$Precision = \\frac{TP}{TP+FP} = \\frac{1}{1+0} = 1$\n",
    "\n",
    "$Recall = \\frac{TP}{TP+FN} = \\frac{1}{1+9} = \\frac{1}{10} = 0.1$\n",
    "\n",
    "$F1-Score = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision+Recall} = 2 \\cdot \\frac{1 \\cdot 0.1}{1+0.1} = 2 \\cdot \\frac{0.1}{1.1} = 0.09$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25742d4-061b-4cae-b0a6-31d75f8ec956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef0763f5-4d79-4ca5-9770-ecaad6f71a5e",
   "metadata": {},
   "source": [
    "## What does the confusion matrix tell us?\n",
    "* üîé Where do we find true positives, false positives, etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e88ae-1977-4689-b19f-6a408c141d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bcc55-8e10-40c8-a9a0-8e76e56f0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf1558-18b9-4f79-a9da-ad3810a34151",
   "metadata": {},
   "source": [
    "# üöÄ We can compute any metric that we wish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff2271-4ebd-4462-94ad-8686377f5bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c546e30-f5bd-4c9f-828b-84f3962bfa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5619f075-d02e-4fe2-90d6-8789c29e98c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434cb41-23c9-4a96-ba50-4b9aaac39d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98c7af7-8630-4c0e-accc-d996841d0bfa",
   "metadata": {},
   "source": [
    "# Can we improve our evaluation process?\n",
    "* Lets try **cross-validation** process for the decision tree model\n",
    "    * https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "* **What is the difference between Pure and Stratified K-Fold?**\n",
    "    * üí° Take a look at the survival ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69807937-742d-4286-ac50-c93d535acdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1003f5ef-aa34-410d-bc7d-abac86a471c8",
   "metadata": {},
   "source": [
    "## After the k-Fold CV is complete we usually want to compute statistics from the desired metric..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a74671-f007-4dda-8bdf-c279a5ff97c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d63087-c259-42b8-87ec-f54aa133fe8b",
   "metadata": {},
   "source": [
    "## ... or create a boxplot out of it üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3a629-0015-41e4-9c51-b6fbee5c3763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2d2bf-acad-4785-9f51-dc573f51f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier(random_state=13)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "    print(f'Survival ratio in train set: {y_train.value_counts(normalize=True)[1]:.2}; Survival ratio in test set: {y_test.value_counts(normalize=True)[1]:.2}')\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736808ff-d46a-49a4-9a1d-b0f5516b37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba458481-daec-4c08-a545-8778a48bfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6be346-e4e6-4a84-8222-9cdfef19e738",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üìä ML algorithms usually have hyper-parameters which change the behaviour of the model\n",
    "* It is usually a good idea to check documentation üòä \n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* For the *DecisionTreeClassifier* a `max_depth` or `min_samples_split` are pretty important\n",
    "\n",
    "* üéØ The goal of the hyper-parameter tuning is to investigate the effect of the parameters on the model and ideally make the model better with setting the right parameters\n",
    "    * Some models are more sensitive to parameters settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c77e54-da34-4dfa-86d6-0599401ee2b7",
   "metadata": {},
   "source": [
    "## üöÄ Let's tune the `max_depth` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74990af-78ea-419f-af00-6348747b0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_global = []\n",
    "\n",
    "scores_global[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f01925-40d5-4ecc-b3f9-7cf63a2fb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_records(scores_global, columns=['max_depth', 'f1'])\n",
    "df_res.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec49336-aea5-4b0c-af6b-157a5af9c5fc",
   "metadata": {},
   "source": [
    "## Now we can plot the data\n",
    "* üîé Which setting is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3f860-0893-44c1-a412-099b0c8043ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_res, x='max_depth', y='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5aacc-e53a-4768-88d3-797093ea8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values(by='f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2df7b5-1d32-4cf7-a8dd-0d2c12131a20",
   "metadata": {},
   "source": [
    "## üöÄ Now we can continue with `min_samples_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30899f96-b953-434d-81ae-d3818607ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_global = []\n",
    "for x in np.arange(2, 50):\n",
    "    skf = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf = DecisionTreeClassifier(min_samples_split = x, random_state = 13)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores.append(f1_score(y_test, y_pred))\n",
    "    scores_global.append((x, np.mean(scores)))\n",
    "        \n",
    "scores_global[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd83c40-aa93-4e75-877d-47b9e3f85f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_records(scores_global, columns=['min_samples_split', 'f1'])\n",
    "df_res.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9603e8-ad8c-47e6-a2b9-bcc00fe07cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_res, x='min_samples_split', y='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99145f32-a602-48e1-80b9-d1939a899d2d",
   "metadata": {},
   "source": [
    "### Which setting is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02640150-13d2-4212-b9c3-6f6e9cb3cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values(by='f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eed6e4-3dda-47fa-bbb2-da1b0b907f06",
   "metadata": {},
   "source": [
    "## üéØ So now we can try the combination of the best parameter-wise settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cac3e-581e-4c92-8de2-8075227b0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=5)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier(max_depth = 8, min_samples_split = 12, random_state = 13)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d5d52-af19-480d-ab33-084630264811",
   "metadata": {},
   "source": [
    "### üîé Is the model now better than the *default* one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533aa52-2edf-49d9-bbad-48d09dd9a167",
   "metadata": {},
   "source": [
    "## Alternatively we can tune both parameters at once üòá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3b429-3773-47cc-98e4-29f84c0710be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_global = []\n",
    "for d in range(2, 25):\n",
    "    for split in range(2, 50):\n",
    "        skf = KFold(n_splits=5)\n",
    "        scores = []\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            clf = DecisionTreeClassifier(max_depth = d, min_samples_split = split, random_state = 13)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            scores.append(f1_score(y_test, y_pred))\n",
    "        scores_global.append((d, split, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc7279-b49f-47fb-a517-2b13a25e9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame.from_records(scores_global, columns=['max_depth', 'min_samples_split', 'f1'])\n",
    "df_res.sort_values(by='f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06db82-c149-44a6-90a1-a785c2de0c2a",
   "metadata": {},
   "source": [
    "## And try the best combination again üòä\n",
    "* üí°You don't have to write these codes by hand, sklearn already provides function for it\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892d821-7256-4d97-9e6d-24cd931b92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=5)\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier(max_depth = 6, min_samples_split = 11, random_state = 13)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65dc8f-cb95-40d7-ba81-c779df06e77b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ‚úÖ Task (2p)\n",
    "* Take a look at the different models in the sklearn\n",
    "    * https://scikit-learn.org/stable/supervised_learning.html\n",
    "* Choose one model that you want to try, check how it works and what hyperparameters are the most important\n",
    "    * You know some of them from the the lectures but you can also check online tutorials, blogs or YouTube üôÇ\n",
    "* Use the model in default settings\n",
    "* Tune at least one of the hyper-parameters and compare the model proposed during the lecture and the one you just created\n",
    "    * Beat the default `DecisionTreeClassifier`\n",
    "\n",
    "* **Describe the insight you got from the experiments with a few sentences in a Markdown cell**\n",
    "    * Mention what parameters you tuned and if the hyperparameter tuning helped!\n",
    "    * ‚ùå Results interpretation figured in real-time during task check is not allowed! ‚ùå\n",
    " \n",
    "![meme03](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_08_meme_03.jpg?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
